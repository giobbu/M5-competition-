{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import math\n",
    "import datetime\n",
    "from math import log, floor\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import pywt\n",
    "from statsmodels.robust import mad\n",
    "\n",
    "\n",
    "import scipy\n",
    "import statsmodels\n",
    "from scipy import signal\n",
    "import statsmodels.api as sm\n",
    "from fbprophet import Prophet\n",
    "from scipy.signal import butter, deconvolve\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, GradientBoostingRegressor\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, parallel_backend\n",
    "from joblib import delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data():\n",
    "    sell_prices_df = pd.read_csv(INPUT_DIR_PATH + 'sell_prices.csv')\n",
    "    sell_prices_df = reduce_mem_usage(sell_prices_df)\n",
    "    print('Sell prices has {} rows and {} columns'.format(sell_prices_df.shape[0], sell_prices_df.shape[1]))\n",
    "\n",
    "    calendar_df = pd.read_csv(INPUT_DIR_PATH + 'calendar.csv')\n",
    "    calendar_df = reduce_mem_usage(calendar_df)\n",
    "    print('Calendar has {} rows and {} columns'.format(calendar_df.shape[0], calendar_df.shape[1]))\n",
    "\n",
    "    sales_train_validation_df = pd.read_csv(INPUT_DIR_PATH + 'sales_train_validation.csv')\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales_train_validation_df.shape[0], sales_train_validation_df.shape[1]))\n",
    "\n",
    "    submission_df = pd.read_csv(INPUT_DIR_PATH + 'sample_submission.csv')\n",
    "    return sell_prices_df, calendar_df, sales_train_validation_df, submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Sales train validation has 30490 rows and 1919 columns\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR_PATH = '../input/m5-forecasting-accuracy/'\n",
    "prices, calendar, sales_train, submission_df = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sales_train\n",
    "\n",
    "del sales_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../input/1-stats-id/1_Z_CA.pkl\", \"rb\") as z1:\n",
    "    Z_1 = z1.read()\n",
    "    \n",
    "with open(\"../input/1-stats-id/1_window_CA.pkl\", \"rb\") as window1:\n",
    "    window_1 = window1.read()\n",
    "    \n",
    "with open(\"../input/1-stats-id/1_list_cal_CA.pkl\", \"rb\") as calendar_1:\n",
    "    calendar_1 = calendar_1.read()\n",
    "\n",
    "\n",
    "Z_3 = pickle.loads(Z_1)\n",
    "\n",
    "window_3 = pickle.loads(window_1)\n",
    "\n",
    "calendar_3 = pickle.loads(calendar_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1437.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.008789</td>\n",
       "      <td>1.010742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1438.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.020508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1441.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6093</th>\n",
       "      <td>1432.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.022461</td>\n",
       "      <td>1.029297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6094</th>\n",
       "      <td>1433.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962891</td>\n",
       "      <td>0.947266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>1434.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>1435.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>1436.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6098 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4         5         6    7      8    9   ...  \\\n",
       "0     1437.0  3.0  1.0  0.0  0.0  1.008789  1.010742  1.0    7.0  3.0  ...   \n",
       "1     1438.0  3.0  1.0  0.0  0.0  1.000000  1.000000  1.0  131.0  1.0  ...   \n",
       "2     1439.0  3.0  1.0  0.0  0.0  1.000000  1.000000  1.0  118.0  1.0  ...   \n",
       "3     1440.0  3.0  1.0  0.0  0.0  1.000000  1.020508  1.0    2.0  2.0  ...   \n",
       "4     1441.0  3.0  1.0  0.0  0.0  1.000000  0.966797  1.0  161.0  4.0  ...   \n",
       "...      ...  ...  ...  ...  ...       ...       ...  ...    ...  ...  ...   \n",
       "6093  1432.0  2.0  0.0  1.0  0.0  1.022461  1.029297  1.0  205.0  5.0  ...   \n",
       "6094  1433.0  2.0  0.0  1.0  0.0  0.962891  0.947266  1.0  124.0  3.0  ...   \n",
       "6095  1434.0  2.0  0.0  1.0  0.0  1.000000  0.965820  1.0  145.0  3.0  ...   \n",
       "6096  1435.0  2.0  0.0  1.0  0.0  1.000000  1.000000  1.0   36.0  1.0  ...   \n",
       "6097  1436.0  2.0  0.0  1.0  0.0  1.000000  1.000000  1.0  125.0  1.0  ...   \n",
       "\n",
       "       54   55   56   57   58   59   60   61   62   63  \n",
       "0     3.0  0.0  1.0  1.0  1.0  3.0  0.0  1.0  1.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     1.0  2.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  0.0  \n",
       "3     0.0  5.0  4.0  1.0  0.0  1.0  3.0  7.0  2.0  0.0  \n",
       "4     1.0  1.0  0.0  1.0  1.0  2.0  2.0  2.0  4.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "6093  2.0  1.0  3.0  1.0  3.0  0.0  2.0  2.0  3.0  2.0  \n",
       "6094  3.0  1.0  1.0  2.0  0.0  1.0  3.0  0.0  1.0  0.0  \n",
       "6095  2.0  0.0  0.0  5.0  0.0  5.0  1.0  1.0  0.0  1.0  \n",
       "6096  1.0  1.0  1.0  2.0  1.0  3.0  0.0  1.0  3.0  1.0  \n",
       "6097  4.0  4.0  2.0  4.0  8.0  3.0  3.0  2.0  0.0  5.0  \n",
       "\n",
       "[6098 rows x 64 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Z_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "from scipy.stats import gmean\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "# def update_statistics(data, n_in_0=1,\n",
    "#                        n_in_1=1,\n",
    "#                        n_in_2=1,\n",
    "#                        n_in_3=1,\n",
    "#                        n_in_4=1,dropnan=True):\n",
    "    \n",
    "# #     n_vars = 1 if type(data) is list else data.shape[1]\n",
    "#     cols_pred, cols_0, cols_1, cols_2, cols_3, cols_4= list(),list(),list(),list(),list(),list()\n",
    "    \n",
    "#     for i in range(0, n_out):\n",
    "#         shif_out = shift(data, -i, mode='constant', cval=-2000).astype(np.float16)\n",
    "#         shif_out[shif_out ==-2000] = np.nan\n",
    "#         cols_pred.append(shif_out)    \n",
    "#     for i in range(28 + n_in_0, 28, -1):\n",
    "#         shif_0 = shift(data, i, mode='constant', cval=-2000).astype(np.float16)\n",
    "#         shif_0 [shif_0 ==-2000] = np.nan\n",
    "#         cols_0.append(shif_0)        \n",
    "#     for i in range(28 + n_in_1, 28,-1):\n",
    "#         shif_1 = shift(data, i, mode='constant', cval=-2000).astype(np.float16)\n",
    "#         shif_1 [shif_1 ==-2000] = np.nan\n",
    "#         cols_1.append(shif_1)        \n",
    "#     for i in range(28 + n_in_2, 28, -1):\n",
    "#         shif_2 = shift(data, i, mode='constant', cval=-2000).astype(np.float16)\n",
    "#         shif_2 [shif_2 ==-2000] = np.nan\n",
    "#         cols_2.append(shif_2)        \n",
    "#     for i in range(28 + n_in_3, 28, -1):\n",
    "#         shif_3 = shift(data, i, mode='constant', cval=-2000).astype(np.float16)\n",
    "#         shif_3 [shif_3 ==-2000] = np.nan\n",
    "#         cols_3.append(shif_3)    \n",
    "#     for i in range(28 + n_in_4, 28, -1):\n",
    "#         shif_4 = shift(data, i, mode='constant', cval=-2000).astype(np.float32)\n",
    "#         shif_4 [shif_4 ==-2000] = np.nan\n",
    "#         cols_4.append(shif_4)        \n",
    "     \n",
    "   \n",
    "#     # put it all together\n",
    "#     agg_out_pred = np.transpose(np.vstack(cols_pred))\n",
    "#     agg_out_0 = np.transpose(np.vstack(cols_0))    \n",
    "#     agg_out_1 = np.transpose(np.vstack(cols_1))    \n",
    "#     agg_out_2 = np.transpose(np.vstack(cols_2))    \n",
    "#     agg_out_3 = np.transpose(np.vstack(cols_3))    \n",
    "#     agg_out_4 = np.transpose(np.vstack(cols_4))\n",
    "    \n",
    "#     med_0 = np.mean(agg_out_0,axis=1).reshape(-1,1)\n",
    "#     std_0 = np.std(agg_out_0,axis=1).reshape(-1,1)\n",
    "    \n",
    "#     med_1 = np.mean(agg_out_1,axis=1).reshape(-1,1)\n",
    "#     std_1 = np.std(agg_out_1,axis=1).reshape(-1,1)\n",
    "    \n",
    "#     med_2 = np.mean(agg_out_2,axis=1).reshape(-1,1)\n",
    "#     std_2 = np.std(agg_out_2,axis=1).reshape(-1,1)\n",
    "    \n",
    "#     med_3 = np.mean(agg_out_3,axis=1).reshape(-1,1)\n",
    "#     std_3 = np.std(agg_out_3,axis=1).reshape(-1,1)\n",
    "    \n",
    "#     med_4 = np.mean(agg_out_4,axis=1).reshape(-1,1)\n",
    "#     std_4 = np.std(agg_out_4,axis=1).reshape(-1,1)\n",
    "\n",
    "\n",
    "#     statistics = np.hstack((std_4, std_3, std_2, std_1,std_0,\n",
    "#                     med_4, med_3, med_2, med_1,med_0))\n",
    "\n",
    "#     updated_stat = statistics[-1,:]#.reshape(1,-1)\n",
    "   \n",
    "#     return updated_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_calendar_statistics(data, n_lags = 1, \n",
    "                       n_in_0=1,\n",
    "                       n_in_1=1,\n",
    "                       n_in_2=1,\n",
    "                       n_in_3=1,\n",
    "                       n_in_4=1,dropnan=True):\n",
    "\n",
    "    \n",
    "    XY = np.zeros((data.shape[0],1))\n",
    "    \n",
    "    DAY = 27\n",
    "    \n",
    "    LAGGING = n_lags\n",
    "    cols = list() \n",
    "    for i in range(LAGGING+DAY, DAY, -1):\n",
    "        shif = shift(data, i, mode='constant', cval=-2000).astype(np.float16)\n",
    "        shif[shif ==-2000] = np.nan\n",
    "        cols.append(shif)\n",
    "    LAGGING_DAY = np.transpose(np.vstack(cols)) \n",
    "    del cols\n",
    "    XY = np.hstack((LAGGING_DAY, XY))\n",
    "\n",
    "    lags = [n_in_0, n_in_1, n_in_2, n_in_3, n_in_4]\n",
    "    for lag in lags:\n",
    "        cols_0 = list() \n",
    "        for i in range( lag+DAY, DAY, -1):\n",
    "            shif_0 = shift(data, i, mode='constant', cval=-2000).astype(np.float32)\n",
    "            shif_0[shif_0 ==-2000] = np.nan\n",
    "            cols_0.append(shif_0)\n",
    "        LAG = np.transpose(np.vstack(cols_0)) \n",
    "        med_0 = np.mean(LAG, axis=1).reshape(-1,1)\n",
    "        std_0 = np.std(LAG, axis=1).reshape(-1,1)\n",
    "        del cols_0, LAG\n",
    "        XY = np.hstack((std_0, med_0, XY))\n",
    "\n",
    "    shifts = [0, 6, 13]\n",
    "    for day in shifts:\n",
    "        lags = [n_in_0, n_in_1, n_in_2, n_in_3]\n",
    "        for lag in lags:\n",
    "            cols = list() \n",
    "            for i in range(lag +day, day, -1):\n",
    "                shif = shift(data, i, mode='constant', cval=-2000).astype(np.float32)\n",
    "                shif[shif ==-2000] = np.nan\n",
    "                cols.append(shif)\n",
    "            LAG_SHIFT = np.transpose(np.vstack(cols)) \n",
    "            med_0 = np.mean(LAG_SHIFT, axis=1).reshape(-1,1)\n",
    "            del cols, LAG_SHIFT\n",
    "            XY = np.hstack((med_0, XY))\n",
    "            \n",
    "    return XY[-1,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dense\n",
    "\n",
    "# n_features = 1\n",
    "# n_steps = 15\n",
    "\n",
    "# def split_sequence(sequence, n_steps):\n",
    "#     X, y = list(), list()\n",
    "#     for i in range(len(sequence)):\n",
    "#         # find the end of this pattern\n",
    "#         end_ix = i + n_steps\n",
    "#         # check if we are beyond the sequence\n",
    "#         if end_ix > len(sequence)-1:\n",
    "#             break\n",
    "#         # gather input and output parts of the pattern\n",
    "#         seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "#         X.append(seq_x)\n",
    "#         y.append(seq_y)\n",
    "#     return np.array(X), np.array(y)\n",
    "\n",
    "# def LSTM_train(sequence, n_steps, n_features):\n",
    "    \n",
    "#     X,y = split_sequence(sequence, n_steps)\n",
    "#     X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "#     # define model\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(optimizer='adam', loss='mse')\n",
    "#     # fit model\n",
    "#     model.fit(X, y, epochs=200, verbose=0)\n",
    "#     return model\n",
    "\n",
    "# LSTM_train(window[int(store)][0][:-2], n_steps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a recursive multi-step forecast\n",
    "def forecast_recursive(model, Z, Window_Frame, list_ID_PR_CAL, lag, mean_0, mean_1,mean_2, mean_3, mean_4):\n",
    "    \n",
    "    # PREDICTIONS FRAME \n",
    "    FRAME_PRED = np.zeros((Z.shape[0],1))\n",
    "    # 1st CYCLE: Recursive Predictions\n",
    "    for j in range(28):\n",
    "        \n",
    "        # Initialisation\n",
    "        if j == 0:\n",
    "            print(Z.shape)\n",
    "            PRED = model.predict(np.delete(Z,[3,4],1)).reshape(-1,1)\n",
    "            NEW_WINDOW = np.hstack((Window_Frame, PRED))\n",
    "            FRAME_PRED = np.hstack((FRAME_PRED, PRED))\n",
    "            print(FRAME_PRED[:,1:])\n",
    "        # Recursive Predictions   \n",
    "        else:\n",
    "            t=0\n",
    "            list_row_z = []\n",
    "            for row in NEW_WINDOW:\n",
    "                stats_updated = update_calendar_statistics(row,\n",
    "                                                           lag,\n",
    "                                                           mean_0,\n",
    "                                                           mean_1,\n",
    "                                                           mean_2,\n",
    "                                                           mean_3,\n",
    "                                                           mean_4).reshape(1,-1) \n",
    "                \n",
    "                id_pr_cal = list_ID_PR_CAL[t][j-1,:].reshape(1,-1)\n",
    "                id_pr_cal = np.delete(id_pr_cal,[3,4],1)\n",
    "                row_z = np.hstack((id_pr_cal, stats_updated))\n",
    "                list_row_z.append(row_z )\n",
    "                t=+1\n",
    "            Z_new = np.vstack(list_row_z)\n",
    "            PRED = model.predict(Z_new).reshape(-1,1)\n",
    "            NEW_WINDOW = np.hstack((NEW_WINDOW, PRED))\n",
    "            FRAME_PRED = np.hstack((FRAME_PRED, PRED))\n",
    "            print(FRAME_PRED[:,1:])\n",
    "            \n",
    "    return FRAME_PRED[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a recursive multi-step forecast\n",
    "def forecast_direct(model, Z, Window_Frame, list_ID_PR_CAL, lag,  mean_0, mean_1,mean_2, mean_3, mean_4):\n",
    "    \n",
    "    # PREDICTIONS FRAME \n",
    "    FRAME_PRED = np.zeros((Z.shape[0],1))\n",
    "    \n",
    "    # 1st CYCLE: Recursive Predictions\n",
    "    for j in range(28):\n",
    "        # Initialisation\n",
    "        if j == 0:\n",
    "            print(Z.shape)\n",
    "            PRED = model.predict(np.delete(Z,[3,4],1)).reshape(-1,1)\n",
    "            FRAME_PRED = np.hstack((FRAME_PRED, PRED))\n",
    "            print(FRAME_PRED[:,1:])\n",
    "        # Direct Predictions   \n",
    "        else:\n",
    "            t=0\n",
    "            list_row_z = []\n",
    "            for row in Z:\n",
    "                statistics = row[27:].reshape(1,-1) \n",
    "                id_pr_cal = list_ID_PR_CAL[t][j-1,:].reshape(1,-1)\n",
    "                id_pr_cal = np.delete(id_pr_cal,[3,4],1)\n",
    "                row_z = np.hstack((id_pr_cal,statistics))\n",
    "                list_row_z.append(row_z )\n",
    "                t=+1\n",
    "            Z_new = np.vstack(list_row_z)\n",
    "            print(Z_new.shape)\n",
    "            PRED = model.predict(Z_new).reshape(-1,1)\n",
    "            FRAME_PRED = np.hstack((FRAME_PRED, PRED))\n",
    "            print(FRAME_PRED[:,1:])\n",
    "        print(j)\n",
    "\n",
    "   \n",
    "    return FRAME_PRED[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "\n",
      "Store\n",
      "0.0\n",
      "\n",
      "(3049, 64)\n",
      "[[0.98378349]\n",
      " [0.26764105]\n",
      " [0.65227121]\n",
      " ...\n",
      " [1.05232275]\n",
      " [1.03064669]\n",
      " [7.06257457]]\n",
      "[[0.98378349 0.83635382]\n",
      " [0.26764105 0.25091975]\n",
      " [0.65227121 0.58060076]\n",
      " ...\n",
      " [1.05232275 0.87818319]\n",
      " [1.03064669 0.86927547]\n",
      " [7.06257457 6.33461125]]\n",
      "[[0.98378349 0.83635382 0.8193798 ]\n",
      " [0.26764105 0.25091975 0.23767631]\n",
      " [0.65227121 0.58060076 0.58177888]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736]\n",
      " [1.03064669 0.86927547 0.85276468]\n",
      " [7.06257457 6.33461125 4.67409175]]\n",
      "[[0.98378349 0.83635382 0.8193798  0.82447408]\n",
      " [0.26764105 0.25091975 0.23767631 0.24287362]\n",
      " [0.65227121 0.58060076 0.58177888 0.57225991]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 0.82177593]\n",
      " [1.03064669 0.86927547 0.85276468 0.83109085]\n",
      " [7.06257457 6.33461125 4.67409175 4.03669056]]\n",
      "[[0.98378349 0.83635382 0.8193798  0.82447408 1.01739837]\n",
      " [0.26764105 0.25091975 0.23767631 0.24287362 0.27116269]\n",
      " [0.65227121 0.58060076 0.58177888 0.57225991 0.7070377 ]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 0.82177593 0.96933614]\n",
      " [1.03064669 0.86927547 0.85276468 0.83109085 0.99281732]\n",
      " [7.06257457 6.33461125 4.67409175 4.03669056 4.92820563]]\n",
      "[[0.98378349 0.83635382 0.8193798  0.82447408 1.01739837 1.25418203]\n",
      " [0.26764105 0.25091975 0.23767631 0.24287362 0.27116269 0.35128394]\n",
      " [0.65227121 0.58060076 0.58177888 0.57225991 0.7070377  0.86527839]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 0.82177593 0.96933614 1.29047892]\n",
      " [1.03064669 0.86927547 0.85276468 0.83109085 0.99281732 1.27814248]\n",
      " [7.06257457 6.33461125 4.67409175 4.03669056 4.92820563 5.15601073]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.01739837 1.25418203 1.32398109]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.27116269 0.35128394 0.35855428]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.7070377  0.86527839 0.88616156]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.96933614 1.29047892 1.27919785]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.99281732 1.27814248 1.31978816]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.92820563 5.15601073 6.37362796]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.25418203 1.32398109 1.05188477]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.35128394 0.35855428 0.28611504]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.86527839 0.88616156 0.66514577]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.29047892 1.27919785 1.03733371]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.27814248 1.31978816 1.04927833]\n",
      " [7.06257457 6.33461125 4.67409175 ... 5.15601073 6.37362796 6.65220929]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.32398109 1.05188477 0.9113015 ]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.35855428 0.28611504 0.26486787]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.88616156 0.66514577 0.60516554]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.27919785 1.03733371 0.88084491]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.31978816 1.04927833 0.85633837]\n",
      " [7.06257457 6.33461125 4.67409175 ... 6.37362796 6.65220929 4.79637836]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.05188477 0.9113015  0.92194151]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.28611504 0.26486787 0.26194363]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.66514577 0.60516554 0.64122671]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.03733371 0.88084491 0.96097333]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.04927833 0.85633837 0.99222694]\n",
      " [7.06257457 6.33461125 4.67409175 ... 6.65220929 4.79637836 4.54757512]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.9113015  0.92194151 0.93956525]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.26486787 0.26194363 0.25112867]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.60516554 0.64122671 0.62802421]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.88084491 0.96097333 0.94774995]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.85633837 0.99222694 0.99670823]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.79637836 4.54757512 4.88971438]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.92194151 0.93956525 1.14547251]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.26194363 0.25112867 0.29418642]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.64122671 0.62802421 0.79771594]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.96097333 0.94774995 1.08854994]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.99222694 0.99670823 1.12297154]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.54757512 4.88971438 5.46586013]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.93956525 1.14547251 1.34896897]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.25112867 0.29418642 0.3518581 ]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.62802421 0.79771594 0.92607611]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.94774995 1.08854994 1.30995841]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.99670823 1.12297154 1.41776479]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.88971438 5.46586013 6.64498432]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.14547251 1.34896897 1.39769253]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.29418642 0.3518581  0.34935584]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.79771594 0.92607611 0.9319967 ]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.08854994 1.30995841 1.33399705]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.12297154 1.41776479 1.36588263]\n",
      " [7.06257457 6.33461125 4.67409175 ... 5.46586013 6.64498432 5.84772705]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.34896897 1.39769253 1.08659277]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.3518581  0.34935584 0.27984265]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.92607611 0.9319967  0.77547464]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.30995841 1.33399705 1.10068402]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.41776479 1.36588263 1.05608066]\n",
      " [7.06257457 6.33461125 4.67409175 ... 6.64498432 5.84772705 5.67589216]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.39769253 1.08659277 0.89319176]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.34935584 0.27984265 0.26304618]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.9319967  0.77547464 0.63059633]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.33399705 1.10068402 0.93010999]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.36588263 1.05608066 0.90974547]\n",
      " [7.06257457 6.33461125 4.67409175 ... 5.84772705 5.67589216 4.08041482]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.08659277 0.89319176 0.87778738]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.27984265 0.26304618 0.26304618]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.77547464 0.63059633 0.62311834]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.10068402 0.93010999 0.92934134]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.05608066 0.90974547 0.97671486]\n",
      " [7.06257457 6.33461125 4.67409175 ... 5.67589216 4.08041482 4.43940962]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.89319176 0.87778738 0.86349866]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.26304618 0.26304618 0.28245907]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.63059633 0.62311834 0.62584083]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.93010999 0.92934134 0.9005945 ]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.90974547 0.97671486 0.9024157 ]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.08041482 4.43940962 4.38749507]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.87778738 0.86349866 1.02644961]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.26304618 0.28245907 0.31074814]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.62311834 0.62584083 0.71085829]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.92934134 0.9005945  1.00366644]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.97671486 0.9024157  1.0543689 ]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.43940962 4.38749507 5.33621949]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.86349866 1.02644961 1.29793697]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.28245907 0.31074814 0.40971389]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.62584083 0.71085829 0.92582581]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.9005945  1.00366644 1.2517145 ]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.9024157  1.0543689  1.30199978]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.38749507 5.33621949 6.51601366]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.02644961 1.29793697 1.3759968 ]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.31074814 0.40971389 0.40571207]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.71085829 0.92582581 0.93493346]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.00366644 1.2517145  1.23933685]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.0543689  1.30199978 1.2783564 ]\n",
      " [7.06257457 6.33461125 4.67409175 ... 5.33621949 6.51601366 5.92382086]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.29793697 1.3759968  1.04823862]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.40971389 0.40571207 0.31190056]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.92582581 0.93493346 0.76493527]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.2517145  1.23933685 0.99888555]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.30199978 1.2783564  1.01260403]\n",
      " [7.06257457 6.33461125 4.67409175 ... 6.51601366 5.92382086 4.84431054]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.3759968  1.04823862 0.86366932]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.40571207 0.31190056 0.27959873]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.93493346 0.76493527 0.6321432 ]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 1.23933685 0.99888555 0.84875349]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.2783564  1.01260403 0.88138717]\n",
      " [7.06257457 6.33461125 4.67409175 ... 5.92382086 4.84431054 3.92860566]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.04823862 0.86366932 0.84033114]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.31190056 0.27959873 0.28870523]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.76493527 0.6321432  0.60409723]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.99888555 0.84875349 0.85166308]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.01260403 0.88138717 0.9615972 ]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.84431054 3.92860566 3.86213381]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.86366932 0.84033114 0.84811002]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.27959873 0.28870523 0.27943849]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.6321432  0.60409723 0.60834299]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.84875349 0.85166308 0.84837223]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.88138717 0.9615972  0.91179291]\n",
      " [7.06257457 6.33461125 4.67409175 ... 3.92860566 3.86213381 4.34729805]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.84033114 0.84811002 1.03197594]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.28870523 0.27943849 0.2997536 ]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.60409723 0.60834299 0.72440034]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.85166308 0.84837223 0.9704625 ]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.9615972  0.91179291 1.03864306]\n",
      " [7.06257457 6.33461125 4.67409175 ... 3.86213381 4.34729805 5.15495228]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 0.84811002 1.03197594 1.34897074]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.27943849 0.2997536  0.38361736]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.60834299 0.72440034 0.97921708]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.84837223 0.9704625  1.27998823]\n",
      " [1.03064669 0.86927547 0.85276468 ... 0.91179291 1.03864306 1.30154185]\n",
      " [7.06257457 6.33461125 4.67409175 ... 4.34729805 5.15495228 6.00557494]]\n",
      "[[0.98378349 0.83635382 0.8193798  ... 1.03197594 1.34897074 1.33219949]\n",
      " [0.26764105 0.25091975 0.23767631 ... 0.2997536  0.38361736 0.3815205 ]\n",
      " [0.65227121 0.58060076 0.58177888 ... 0.72440034 0.97921708 0.95624461]\n",
      " ...\n",
      " [1.05232275 0.87818319 0.83006736 ... 0.9704625  1.27998823 1.22908909]\n",
      " [1.03064669 0.86927547 0.85276468 ... 1.03864306 1.30154185 1.31797609]\n",
      " [7.06257457 6.33461125 4.67409175 ... 5.15495228 6.00557494 6.18138814]]\n",
      "\n",
      "Store\n",
      "1.0\n",
      "\n",
      "(3049, 64)\n",
      "[[0.69277409]\n",
      " [0.18486835]\n",
      " [0.38801165]\n",
      " ...\n",
      " [0.90444328]\n",
      " [0.94436694]\n",
      " [3.73387842]]\n",
      "[[0.69277409 0.66440821]\n",
      " [0.18486835 0.17519156]\n",
      " [0.38801165 0.37177335]\n",
      " ...\n",
      " [0.90444328 0.80380834]\n",
      " [0.94436694 0.85064701]\n",
      " [3.73387842 3.19017208]]\n",
      "[[0.69277409 0.66440821 0.6734573 ]\n",
      " [0.18486835 0.17519156 0.17498616]\n",
      " [0.38801165 0.37177335 0.36558938]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049]\n",
      " [0.94436694 0.85064701 0.902056  ]\n",
      " [3.73387842 3.19017208 2.88477428]]\n",
      "[[0.69277409 0.66440821 0.6734573  0.64055738]\n",
      " [0.18486835 0.17519156 0.17498616 0.17519156]\n",
      " [0.38801165 0.37177335 0.36558938 0.3743069 ]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 0.8668661 ]\n",
      " [0.94436694 0.85064701 0.902056   0.85343568]\n",
      " [3.73387842 3.19017208 2.88477428 3.42256009]]\n",
      "[[0.69277409 0.66440821 0.6734573  0.64055738 0.78498859]\n",
      " [0.18486835 0.17519156 0.17498616 0.17519156 0.21839516]\n",
      " [0.38801165 0.37177335 0.36558938 0.3743069  0.44421184]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 0.8668661  0.98875979]\n",
      " [0.94436694 0.85064701 0.902056   0.85343568 0.95154656]\n",
      " [3.73387842 3.19017208 2.88477428 3.42256009 3.71392631]]\n",
      "[[0.69277409 0.66440821 0.6734573  0.64055738 0.78498859 1.02556874]\n",
      " [0.18486835 0.17519156 0.17498616 0.17519156 0.21839516 0.32365536]\n",
      " [0.38801165 0.37177335 0.36558938 0.3743069  0.44421184 0.62410959]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 0.8668661  0.98875979 1.30235964]\n",
      " [0.94436694 0.85064701 0.902056   0.85343568 0.95154656 1.30749884]\n",
      " [3.73387842 3.19017208 2.88477428 3.42256009 3.71392631 5.02147012]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.78498859 1.02556874 1.01220094]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.21839516 0.32365536 0.2996058 ]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.44421184 0.62410959 0.62518293]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.98875979 1.30235964 1.32419402]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.95154656 1.30749884 1.30889061]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.71392631 5.02147012 5.03807683]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 1.02556874 1.01220094 0.76794838]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.32365536 0.2996058  0.20077279]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.62410959 0.62518293 0.46008239]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.30235964 1.32419402 1.02656666]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.30749884 1.30889061 0.97461566]\n",
      " [3.73387842 3.19017208 2.88477428 ... 5.02147012 5.03807683 4.38290072]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 1.01220094 0.76794838 0.662554  ]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.2996058  0.20077279 0.18642609]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.62518293 0.46008239 0.39817776]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.32419402 1.02656666 0.86927314]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.30889061 0.97461566 0.86330819]\n",
      " [3.73387842 3.19017208 2.88477428 ... 5.03807683 4.38290072 3.27420413]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.76794838 0.662554   0.66584949]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.20077279 0.18642609 0.19782667]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.46008239 0.39817776 0.43074912]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.02656666 0.86927314 0.94422946]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.97461566 0.86330819 0.93443525]\n",
      " [3.73387842 3.19017208 2.88477428 ... 4.38290072 3.27420413 3.62875956]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.662554   0.66584949 0.69448303]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.18642609 0.19782667 0.19668338]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.39817776 0.43074912 0.42205101]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.86927314 0.94422946 0.928939  ]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.86330819 0.93443525 0.85806156]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.27420413 3.62875956 3.92511559]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.66584949 0.69448303 0.75638509]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.19782667 0.19668338 0.22249865]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.43074912 0.42205101 0.45754119]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.94422946 0.928939   1.09930308]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.93443525 0.85806156 1.02837376]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.62875956 3.92511559 4.10027484]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.69448303 0.75638509 1.01978061]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.19668338 0.22249865 0.31378215]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.42205101 0.45754119 0.65885341]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.928939   1.09930308 1.40207872]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.85806156 1.02837376 1.32587675]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.92511559 4.10027484 5.44227443]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.75638509 1.01978061 1.00608359]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.22249865 0.31378215 0.3117744 ]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.45754119 0.65885341 0.64118039]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.09930308 1.40207872 1.35898431]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.02837376 1.32587675 1.31807742]\n",
      " [3.73387842 3.19017208 2.88477428 ... 4.10027484 5.44227443 5.16888918]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 1.01978061 1.00608359 0.68502555]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.31378215 0.3117744  0.20428023]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.65885341 0.64118039 0.42156849]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.40207872 1.35898431 0.94140114]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.32587675 1.31807742 0.87808536]\n",
      " [3.73387842 3.19017208 2.88477428 ... 5.44227443 5.16888918 3.74641971]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 1.00608359 0.68502555 0.65509968]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.3117744  0.20428023 0.18379075]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.64118039 0.42156849 0.41650456]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.35898431 0.94140114 0.87803006]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.31807742 0.87808536 0.81078848]\n",
      " [3.73387842 3.19017208 2.88477428 ... 5.16888918 3.74641971 3.45353251]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.68502555 0.65509968 0.66334184]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.20428023 0.18379075 0.18480858]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.42156849 0.41650456 0.42709504]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.94140114 0.87803006 0.86121005]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.87808536 0.81078848 0.83764818]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.74641971 3.45353251 3.41635984]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.65509968 0.66334184 0.6575421 ]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.18379075 0.18480858 0.18480858]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.41650456 0.42709504 0.42179317]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.87803006 0.86121005 0.81753228]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.81078848 0.83764818 0.84023858]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.45353251 3.41635984 3.62757206]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.66334184 0.6575421  0.79904204]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.18480858 0.18480858 0.21057499]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.42709504 0.42179317 0.48069603]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.86121005 0.81753228 1.00215981]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.83764818 0.84023858 1.00487368]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.41635984 3.62757206 4.08342165]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.6575421  0.79904204 1.12511248]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.18480858 0.21057499 0.28562483]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.42179317 0.48069603 0.66184631]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.81753228 1.00215981 1.34297268]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.84023858 1.00487368 1.35717003]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.62757206 4.08342165 5.63225865]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.79904204 1.12511248 1.05925795]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.21057499 0.28562483 0.27620492]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.48069603 0.66184631 0.66507215]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.00215981 1.34297268 1.39184567]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.00487368 1.35717003 1.33541529]\n",
      " [3.73387842 3.19017208 2.88477428 ... 4.08342165 5.63225865 5.22373002]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 1.12511248 1.05925795 0.71346077]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.28562483 0.27620492 0.19784873]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.66184631 0.66507215 0.45584084]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.34297268 1.39184567 0.98298268]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.35717003 1.33541529 0.90229426]\n",
      " [3.73387842 3.19017208 2.88477428 ... 5.63225865 5.22373002 3.38264506]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 1.05925795 0.71346077 0.7025631 ]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.27620492 0.19784873 0.19464975]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.66507215 0.45584084 0.44236407]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.39184567 0.98298268 0.89026858]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.33541529 0.90229426 0.86127742]\n",
      " [3.73387842 3.19017208 2.88477428 ... 5.22373002 3.38264506 3.4535966 ]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.71346077 0.7025631  0.69884316]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.19784873 0.19464975 0.19890673]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.45584084 0.44236407 0.45783977]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.98298268 0.89026858 0.87791526]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.90229426 0.86127742 0.91049793]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.38264506 3.4535966  3.32159273]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.7025631  0.69884316 0.69415164]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.19464975 0.19890673 0.19890673]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.44236407 0.45783977 0.44300062]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.89026858 0.87791526 0.8872563 ]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.86127742 0.91049793 0.87306154]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.4535966  3.32159273 3.37112174]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.69884316 0.69415164 0.82123856]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.19890673 0.19890673 0.22677243]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.45783977 0.44300062 0.50504489]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.87791526 0.8872563  1.05381115]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.91049793 0.87306154 1.01693244]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.32159273 3.37112174 4.22942459]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.69415164 0.82123856 1.1242817 ]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.19890673 0.22677243 0.31768304]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.44300062 0.50504489 0.69808612]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 0.8872563  1.05381115 1.42343069]\n",
      " [0.94436694 0.85064701 0.902056   ... 0.87306154 1.01693244 1.370264  ]\n",
      " [3.73387842 3.19017208 2.88477428 ... 3.37112174 4.22942459 5.17325063]]\n",
      "[[0.69277409 0.66440821 0.6734573  ... 0.82123856 1.1242817  1.0226076 ]\n",
      " [0.18486835 0.17519156 0.17498616 ... 0.22677243 0.31768304 0.28171328]\n",
      " [0.38801165 0.37177335 0.36558938 ... 0.50504489 0.69808612 0.65130421]\n",
      " ...\n",
      " [0.90444328 0.80380834 0.83751049 ... 1.05381115 1.42343069 1.37916366]\n",
      " [0.94436694 0.85064701 0.902056   ... 1.01693244 1.370264   1.30054207]\n",
      " [3.73387842 3.19017208 2.88477428 ... 4.22942459 5.17325063 5.27902897]]\n"
     ]
    }
   ],
   "source": [
    "n_out = 1\n",
    "n_lags = 15\n",
    "n_0 = 7\n",
    "n_1 = 14\n",
    "n_2 = 30\n",
    "n_3 = 60\n",
    "n_4 = 180\n",
    "\n",
    "\n",
    "w1 = window_3[:3049,:]\n",
    "w2 = window_3[3049:6098,:]\n",
    "\n",
    "window = [w1,w2]\n",
    "\n",
    "STORES = np.unique(Z_3[:,3])\n",
    "print(STORES)\n",
    "list_stores=[]\n",
    "for store in STORES:\n",
    "    print('')\n",
    "    print('Store')\n",
    "    print(store)\n",
    "    print('')\n",
    "    zi_store = Z_3[Z_3[:,3]==store]\n",
    "    model = lgb.Booster(model_file='../input/model-train/model_ca_'+str(int(store))+'.txt')\n",
    "    store_forecasts = forecast_recursive(model, zi_store, window[int(store)], calendar_3, \n",
    "                                         n_lags, n_0, n_1, n_2, n_3, n_4)\n",
    "    list_stores.append(store_forecasts)\n",
    "    \n",
    "df = np.vstack(list_stores)\n",
    "forecast = pd.DataFrame(df)\n",
    "forecast.to_csv('forecast_CA_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = forecast_reverse(model, Z_3, window_3, calendar_3, n_0, n_1, n_2, n_3, n_4, n_5, n_6)\n",
    "# forecast = pd.DataFrame(df)\n",
    "# forecast.to_csv('forecast_CA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast = pd.read_csv(\"../input/1-pred-ca/forecast_diff_CA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast = pd.DataFrame([[-0.38658618,  0.03515502, -0.36224897],\n",
    "#                          [0.18962422,  1.53729267, -0.16193974],\n",
    "#                          [-0.60323886 ,-0.02146203, -0.11368382]])\n",
    "\n",
    "# df_window = pd.DataFrame(window_sqrt_diff)\n",
    "# transf = pd.concat([df_window, forecast],axis=1).fillna(0)\n",
    "# v0 = v0.reshape(-1,1)\n",
    "\n",
    "# transf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(np.square(np.hstack((v0, transf)).cumsum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0 = window_dataset[:,0]\n",
    "# diff_window_df = pd.DataFrame(window_dataset).diff(axis=1)\n",
    "# df_forecast_diff = pd.concat([diff_window_df, forecast],axis=1)\n",
    "# df_forecast_diff\n",
    "# df_v0 = df_forecast_diff.expanding(0,axis=1).sum()\n",
    "# # for t in range (len(df_v0)):\n",
    "# #     df_v0.iloc[t,:] = df_v0.iloc[t,:] + v0[t]\n",
    "    \n",
    "# df_v0.iloc[:,:]#.to_csv('forecast_CA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
